{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "from IPython.display import Audio\n",
    "import librosa\n",
    "import scipy as sp\n",
    "from numba import jit\n",
    "from scipy.spatial import distance\n",
    "\n",
    "figsize(20,6)\n",
    "prefix=\"baseline\"\n",
    "def filepre(nm):\n",
    "    return \"tmp/\"+prefix+\"_\"+nm\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "%aimport microbial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def nrmse(output,target):\n",
    "    assert(output.shape[0] == target.shape[0])\n",
    "    combinedVar = 0.5 * (np.var(target, ddof=1) + np.var(output, ddof=1))\n",
    "    errorSignal = output - target\n",
    "    return np.sqrt(np.mean(errorSignal ** 2) / combinedVar)\n",
    "\n",
    "def generateInternalWeights(nInternalUnits, connectivity):\n",
    "    success = False\n",
    "    internalWeights = 0\n",
    "    while success == False:\n",
    "        try:\n",
    "            internalWeights = np.random.randn(nInternalUnits,nInternalUnits) * (np.random.random((nInternalUnits,nInternalUnits)) < connectivity)\n",
    "            specRad = max(abs(np.linalg.eig(internalWeights)[0]))\n",
    "            if (specRad > 0):\n",
    "                internalWeights = internalWeights / specRad\n",
    "                success = True\n",
    "        except e:\n",
    "            print(e)\n",
    "    return internalWeights\n",
    "\n",
    "pLoop = lambda n,p: p[n%p.size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "resultsFolderName = \"fbsynthResults/results\" + str(datetime.now()) + \"/\"\n",
    "os.mkdir(resultsFolderName)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_path = \"audios/ixi\"\n",
    "ixiFiles = [fn for fn in os.listdir(relevant_path)\n",
    "              if fn.endswith('wav')]\n",
    "print(ixiFiles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ixistr(id):\n",
    "    return str(id) + \"_\" + ixiFiles[id] + \"_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compareMFCCs(seq1, seq2):\n",
    "    fftSize=2048\n",
    "    hop=64    \n",
    "    melspec = librosa.feature.melspectrogram(y=seq1, sr=sr, n_fft=fftSize,hop_length=hop)\n",
    "    mfccs = librosa.feature.mfcc(S=melspec,n_mfcc=20)[1:,:]\n",
    "    melspec2 = librosa.feature.melspectrogram(y=seq2, sr=sr, n_fft=fftSize,hop_length=hop)\n",
    "    mfccs2 = librosa.feature.mfcc(S=melspec2,n_mfcc=20)[1:,:]    \n",
    "    return nrmse(mfccs.flatten(), mfccs2.flatten())\n",
    "        \n",
    "\n",
    "def evoEvalFeedbackModel(patterns, patternLengths, N, lr, biasScale, inScale, plotResult=False):\n",
    "    print(\"Eval model, args: \", N, lr)\n",
    "    W = generateInternalWeights(N, 10.0/N)\n",
    "    Win = (np.random.rand(N, 1) - 0.5) * 2 * inScale\n",
    "    Wbias = (np.random.rand(N, 1) - 0.5) * biasScale\n",
    "    x = (np.random.rand(N, 1) - 0.5) \n",
    "    orgX = x.copy()\n",
    "    firstPattern=0\n",
    "    lastPattern = patterns.shape[0]\n",
    "    sequences = patterns[firstPattern:lastPattern]\n",
    "    # sequence1 = [patterns[startPattern+0].take(x, mode='wrap') for x in range(seqLen)] #pow(sin(arange(seqLen)/4),1) * 0.5\n",
    "\n",
    "    trainLen = sum(patternLengths[firstPattern:lastPattern]) - sequences.shape[0]\n",
    "    washoutLen= 50\n",
    "\n",
    "\n",
    "    loadingTrials = 1\n",
    "    loadingTrialResults = zeros(loadingTrials)\n",
    "    bestLoadingError=999\n",
    "    bestW = W.copy()\n",
    "    bestWin = Win.copy()\n",
    "    bestWbias = Wbias.copy()\n",
    "    for loadingTrial in range(loadingTrials):\n",
    "        W = generateInternalWeights(N, 10.0/N) * 0.2\n",
    "        Win = (np.random.rand(N, 1) - 0.5) * 2\n",
    "        Wbias = (np.random.rand(N, 1) - 0.5) * 0.1\n",
    "        #run to washout\n",
    "        for n in range(washoutLen):\n",
    "            xOld = x\n",
    "            Wtarget = (W.dot(x)) + (Win.dot(sequences[0].take(n, mode='wrap')))\n",
    "            newX =lr * tanh(Wtarget + Wbias)\n",
    "            oldX = (1 - lr) * xOld\n",
    "            x = newX + oldX \n",
    "\n",
    "        #observe to adjust W - load patterns into the network\n",
    "        xOldCollector = np.zeros((N, trainLen));    \n",
    "        WTargetCollector = np.zeros((N, trainLen)); \n",
    "        trainIdx = 0\n",
    "        for seq in range(sequences.shape[0]):\n",
    "            for n in range(patternLengths[firstPattern + seq]-1):\n",
    "                xOld = x\n",
    "                Wtarget = (W.dot(x)) + (Win.dot(sequences[seq][n]))\n",
    "                newX =lr * tanh(Wtarget + Wbias)\n",
    "                oldX = (1 - lr) * xOld\n",
    "                x = newX + oldX \n",
    "\n",
    "                xOldCollector[:, trainIdx] = xOld[:,0]\n",
    "                WTargetCollector[:, trainIdx] = Wtarget[:,0]\n",
    "                trainIdx = trainIdx + 1\n",
    "\n",
    "\n",
    "        W = (linalg.inv(xOldCollector.dot(xOldCollector.T) +\n",
    "                          (1e-5 * np.eye(N))).dot(xOldCollector).dot(WTargetCollector.T)).T\n",
    "\n",
    "        NRMSE_W = mean(nrmse(W.dot(xOldCollector), WTargetCollector))\n",
    "        absSize_W = mean(mean(abs(W), axis=0))\n",
    "#         print(\"W error: \", NRMSE_W, absSize_W)\n",
    "        loadingTrialResults[loadingTrial] = NRMSE_W\n",
    "        if (NRMSE_W < bestLoadingError):\n",
    "            bestLoadingError = NRMSE_W\n",
    "            bestW = W.copy()\n",
    "            bestWin = Win.copy()\n",
    "            bestWbias = Wbias.copy()\n",
    "\n",
    "\n",
    "    W = bestW.copy()\n",
    "    Win = bestWin.copy()\n",
    "    Wbias = bestWbias.copy()\n",
    "\n",
    "    print(\"Mean loading error: \", mean(loadingTrialResults))\n",
    "\n",
    "\n",
    "    Wouts = np.zeros((sequences.shape[0], N+1)); \n",
    "    cues = np.zeros((N,sequences.shape[0])); \n",
    "\n",
    "    # x = orgX.copy()\n",
    "    x = 0.5 * np.random.randn(N,1)\n",
    "\n",
    "\n",
    "    #run to washout\n",
    "    for n in range(washoutLen):\n",
    "        xOld = x\n",
    "        Wtarget = (W.dot(x)) + (Win.dot(sequences[0].take(n, mode='wrap')))\n",
    "        newX =lr * tanh(Wtarget + Wbias )\n",
    "        oldX = (1 - lr) * xOld\n",
    "        x = newX + oldX \n",
    "\n",
    "    allTrain = zeros(trainLen)\n",
    "\n",
    "    trainIdx = 0\n",
    "    readOutErrors = zeros(sequences.shape[0])\n",
    "    readOutErrorsMel = zeros(sequences.shape[0])\n",
    "    for seq in range(sequences.shape[0]):\n",
    "        seqLen = sequences[seq].shape[0]\n",
    "        xCollector = np.zeros((N + 1, seqLen-1));    \n",
    "        pCollector = np.zeros((1, seqLen-1));  \n",
    "        for n in range(seqLen-1):\n",
    "            xOld = x\n",
    "            u = sequences[seq][n]\n",
    "            Wtarget = (W.dot(x)) + (Win.dot(u))\n",
    "            newX =lr * tanh(Wtarget + Wbias )\n",
    "            oldX = (1 - lr) * xOld\n",
    "            x = newX + oldX \n",
    "\n",
    "            xCollector[:, n] = np.concatenate((x[:,0], np.array([1])))\n",
    "            pCollector[0, n] = sequences[seq][n+1]\n",
    "            allTrain[trainIdx] = u\n",
    "            trainIdx = trainIdx+1\n",
    "\n",
    "        Wouts[seq] = hstack(linalg.inv(xCollector.dot(xCollector.T) + (1e-5 * np.eye(N + 1))).dot(xCollector).dot(pCollector.T))\n",
    "        cues[:, seq] = x[:,0]\n",
    "\n",
    "        outsRecovered = Wouts[seq].dot(xCollector);\n",
    "        NRMSE_readout = mean(nrmse(outsRecovered, pCollector[0,:]))\n",
    "        absSize_readout = mean(mean(abs(Wouts[seq]), axis=0))\n",
    "#         print(\"Wout error \" + str(seq) + \": \", NRMSE_readout, absSize_readout)\n",
    "\n",
    "        readOutErrorsMel[seq] = compareMFCCs(outsRecovered, pCollector[0,:])\n",
    "#         print(\"Wout mel error \" + str(seq) + \": \", readOutErrorsMel[seq])\n",
    "\n",
    "        readOutErrors[seq] = NRMSE_readout\n",
    "\n",
    "    meanReadoutError = mean(readOutErrors)\n",
    "    meanMelReadoutError = mean(readOutErrorsMel)\n",
    "    print(\"Mean readout error: \", meanReadoutError, \", mean mel readout error: \", meanMelReadoutError)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    results = zeros(sequences.shape[0])\n",
    "\n",
    "    for cueIdx in range(sequences.shape[0]):\n",
    "#             print(\"Cue: \", cueIdx)\n",
    "        runLen = sequences[cueIdx].shape[0] * 4\n",
    "        outCollector = np.zeros((1, runLen));  \n",
    "\n",
    "        x = cues[:,[cueIdx]]\n",
    "\n",
    "        for n in range(runLen):  \n",
    "            xOld = x\n",
    "            Wtarget = (W.dot(x)) + (Win.dot(u))\n",
    "            newX =lr * tanh(Wtarget + Wbias)\n",
    "            oldX = (1 - lr) * xOld\n",
    "            x = newX + oldX \n",
    "            u = Wouts[cueIdx].dot(np.concatenate((x[:,0], np.array([1]))))\n",
    "            outCollector[0, n] = u\n",
    "\n",
    "        targetPattern = array([sequences[cueIdx].take(x,mode='wrap') for x in range(runLen)])\n",
    "        templateScan = np.correlate(outCollector[0][:sequences[cueIdx].shape[0]*2],sequences[cueIdx])\n",
    "        matchPoint = np.argmax(templateScan)\n",
    "        outputPattern = outCollector[0]\n",
    "        if (matchPoint > 0):\n",
    "            outputPattern = outputPattern[matchPoint:]\n",
    "            targetPattern = targetPattern[:-matchPoint]\n",
    "        evalLen = sequences[cueIdx].shape[0] * 2\n",
    "\n",
    "        results[cueIdx] = compareMFCCs(outputPattern[-evalLen:], targetPattern[-evalLen:])\n",
    "        if plotResult:\n",
    "            figsize(20,60)\n",
    "            ax = subplot(sequences.shape[0], 1, cueIdx+1)\n",
    "            ax.set_title(\"Sequence \" + str(cueIdx) + \", NRMSE: \" + str(results[cueIdx]))    \n",
    "            plot(outputPattern)\n",
    "            plot(targetPattern)\n",
    "#             print(\"NRMSE: \", results[cueIdx])\n",
    "\n",
    "    meanRes = median(results)\n",
    "    print(\"Median error: \", meanRes)\n",
    "    cueSequence = zeros((sequences.shape[0],2), dtype=int)\n",
    "    for i in range(sequences.shape[0]-1):\n",
    "        cueSequence[i+1][0] = sequences[i].shape[0] + cueSequence[i][0]\n",
    "        cueSequence[i+1][1] = i+1\n",
    "    return {\"res\":meanRes, \"model\":{'W':W, 'Win':Win, 'Wbias':Wbias, 'Wouts':Wouts, \n",
    "                                    'cueSequence':cueSequence, 'N':N, 'lr':lr,\n",
    "                                    'trainingSeq':allTrain}}\n",
    "\n",
    "def evoEvalFeedbackSynthesis(model, plotResult=False, lrMod=1, cue=None):\n",
    "#     print(\"Resynthesis, lr: \", model['lr'] * lrMod)\n",
    "    runLen = model['trainingSeq'].shape[0]\n",
    "#     print(\"Runlen: \",runLen)\n",
    "    u = 0\n",
    "    x=None\n",
    "    if (cue is None):\n",
    "        x = 0.5 * np.random.randn(model['N'],1)\n",
    "    else:\n",
    "        x = cue\n",
    "    cue = x.copy()\n",
    "    LR = model['lr'] * lrMod\n",
    "    #run to washout\n",
    "    for n in range(50):\n",
    "        xOld = x\n",
    "        Wtarget = (model['W'].dot(x)) + (model['Win'].dot(u))\n",
    "        newX =LR * tanh(Wtarget + model['Wbias'])\n",
    "        oldX = (1 - LR) * xOld\n",
    "        x = newX + oldX \n",
    "        u = model['Wouts'][0].dot(np.concatenate((x[:,0], np.array([1]))))\n",
    "\n",
    "    outCollector = np.zeros((1, runLen));  \n",
    "    cueSequence = model['cueSequence'].copy()\n",
    "    cueIdx=0\n",
    "    nextCue = cueSequence[0]\n",
    "    for n in range(runLen):\n",
    "        if (n == nextCue[0]):\n",
    "            cueIdx = nextCue[1]\n",
    "    #         x = cues[:,cueIdx]\n",
    "    #         u = sequences[cueIdx][0]\n",
    "            if (cueSequence.shape[0] > 1):\n",
    "                cueSequence = cueSequence[1:]\n",
    "                nextCue = cueSequence[0]\n",
    "#                 print(cueIdx, end=\"'\")\n",
    "\n",
    "        xOld = x\n",
    "        Wtarget = (model['W'].dot(x)) + (model['Win'].dot(u))\n",
    "        newX =LR * tanh(Wtarget + model['Wbias'])\n",
    "        oldX = (1 - LR) * xOld\n",
    "        x = newX + oldX \n",
    "        u = model['Wouts'][cueIdx].dot(np.concatenate((x[:,0], np.array([1]))))\n",
    "        outCollector[0, n] = u\n",
    "#         print (model['trainingSeq'].shape, outCollector.shape)\n",
    "    error = compareMFCCs(outCollector[0], model['trainingSeq'])\n",
    "#     print(\"Error: \", error)\n",
    "\n",
    "    if (plotResult):\n",
    "        print(\"Plotting results\")\n",
    "        figsize(20,3)\n",
    "        figure(1)\n",
    "        plot(model['trainingSeq'])\n",
    "        plot(outCollector[0])\n",
    "        figure(2)\n",
    "        plot(outCollector[0])\n",
    "    return {\"error\":error, \"waveform\":outCollector[0], \"cue\":cue}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def evalModel(params, patterns, patternLengths, modelcount, synthcount):\n",
    "    bestScore=99999\n",
    "    bestModel={}\n",
    "    bestResult = {}\n",
    "    \n",
    "    for i in range(modelcount):\n",
    "        modelEvalResult = evoEvalFeedbackModel(patterns, patternLengths, int(20 + (params[0] * 880)), params[1], params[2], params[3] * 1)\n",
    "        for j in range(synthcount):\n",
    "            synthesisResult = evoEvalFeedbackSynthesis(modelEvalResult[\"model\"], False)\n",
    "            score = synthesisResult[\"error\"]\n",
    "            print(score, end=',')\n",
    "            if score < bestScore:\n",
    "                bestResult = synthesisResult\n",
    "                bestScore = score\n",
    "                bestModel = modelEvalResult[\"model\"]\n",
    "                print(\"@@\")\n",
    "        print(\"\")\n",
    "    return {\"bestModel\":bestModel, \"bestScore\": bestScore, \"bestResult\":bestResult}\n",
    "                \n",
    "def evalFitness(params, data):\n",
    "\n",
    "    bestModelData = evalModel(params, data['patterns'], data['patternLengths'], 15, 10)\n",
    "    if (\"winner\" in data):\n",
    "        if bestModelData['bestScore'] < data['winner']['bestScore']:\n",
    "            data['winner'] = bestModelData\n",
    "    else:\n",
    "        data['winner'] = bestModelData\n",
    "    return bestModelData[\"bestScore\"]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "startTS = datetime.now()\n",
    "for currentIxi in range(len(ixiFiles)):\n",
    "    clear_output()\n",
    "    print(\"loading: \", ixiFiles[currentIxi])\n",
    "    y, sr = librosa.load(\"audios/ixi/\" + ixiFiles[currentIxi], sr=22050)\n",
    "    y = y[:5000] / np.max(y) * 0.5\n",
    "    print(sr)\n",
    "\n",
    "    #divide out windows\n",
    "    patterns = []\n",
    "\n",
    "    minPatternSize = 9\n",
    "    lastCrossing=0\n",
    "    for i in range(y.shape[0]-1):\n",
    "        if (i-lastCrossing) > minPatternSize and y[i] >=0 and y[i+1] < 0:\n",
    "            print(i)\n",
    "            segment = y[lastCrossing:i]\n",
    "            patterns.append(segment)\n",
    "            lastCrossing = i\n",
    "            \n",
    "    #convert to numpy\n",
    "    patterns = np.array(patterns, dtype=np.object)\n",
    "    maxPatterns = 150\n",
    "    patterns = patterns[:maxPatterns]\n",
    "    patternLengths = [x.shape[0] for x in patterns]\n",
    "    y = y[:sum(patternLengths)]\n",
    "    maxPatternLen = np.max(patternLengths)\n",
    "    minPatternLen = np.min(patternLengths)\n",
    "    print(\"max length: \", maxPatternLen)\n",
    "    print(\"min length: \", minPatternLen)\n",
    "    # for p in patterns:\n",
    "    #     plot(p)\n",
    "    print(patterns.shape)\n",
    "    \n",
    "    pop = microbial.createPop(8, 4, 99999) \n",
    "    \n",
    "    data = {'patterns':patterns, 'patternLengths':patternLengths}\n",
    "    def onEpochStart():\n",
    "        clear_output()\n",
    "        print('Runtime:', print(datetime.now() - startTS))\n",
    "        print(currentIxi, '/', len(ixiFiles), ' : ', ixiFiles[currentIxi])\n",
    "        f = open(resultsFolderName + ixistr(currentIxi) + \"evoLog.txt\", \"a\")\n",
    "        f.write(str(pop))\n",
    "        f.close()\n",
    "\n",
    "    microbial.evolve(pop, evalFitness, microbial.criterionMin, data, 4, 50, 0.2, 0.5, 0.5 , onEpochStart)\n",
    "    \n",
    "    plt.close()\n",
    "    figsize(20,4)\n",
    "    plt.xlabel(\"Time (samples)\", fontsize=20)\n",
    "    plt.ylabel(\"Amplitude\", fontsize=20)\n",
    "    plt.xticks(fontsize=18, rotation=0)\n",
    "    plt.yticks(fontsize=18, rotation=0) \n",
    "    plot(y[:data['winner']['bestResult']['waveform'].shape[0]], label='Original', alpha=0.6)\n",
    "    plot(data['winner']['bestResult']['waveform'], alpha=1.0, label='Reconstruction')\n",
    "    plt.legend(fontsize=20)\n",
    "    plt.savefig(resultsFolderName + ixistr(currentIxi) + \"compare.pdf\", bbox_inches='tight')\n",
    "\n",
    "    librosa.output.write_wav(resultsFolderName + ixistr(currentIxi) + \"org.wav\",y, sr)\n",
    "    librosa.output.write_wav(resultsFolderName + ixistr(currentIxi) + \"recon.wav\", data['winner']['bestResult']['waveform'], sr)\n",
    "\n",
    "    import dill as pickle\n",
    "    with open(resultsFolderName + ixistr(currentIxi) + r\"model.dill.pickled\", \"wb\") as output_file:    \n",
    "        pickle.dump({'winner':data['winner'], 'pop':pop, 'original':y, 'patterns':patterns}, output_file, protocol=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
